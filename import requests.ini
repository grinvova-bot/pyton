import time
from selenium import webdriver
from selenium.webdriver.common.by import By
from bs4 import BeautifulSoup
import pandas as pd

# URL страницы, с которой будем парсить цены и названия товаров
url = 'https://alt-x.ru/catalog/kraski_emali/aerozolnye_kraski_v_ballonchikakh/'

# Инициализация WebDriver (убедитесь, что путь к WebDriver правильный)
driver = webdriver.Chrome(executable_path='path/to/chromedriver')

# Открываем страницу
driver.get(url)

# Ждем, пока страница полностью загрузится (можно использовать WebDriverWait для более точного ожидания)
time.sleep(5)

# Получаем содержимое страницы
page_content = driver.page_source

# Создаем объект BeautifulSoup для парсинга HTML
soup = BeautifulSoup(page_content, 'html.parser')

# Находим все элементы с ценами (предположим, что цены находятся в тегах <span> с классом 'price_value')
price_elements = soup.find_all('span', class_='price_value')

# Находим все элементы с названиями товаров (предположим, что названия находятся в тегах <span> внутри <div> с классом 'item-title')
title_elements = soup.find_all('div', class_='item-title')

# Извлекаем текст из каждого элемента и сохраняем его в списки
prices = [price_element.get_text(strip=True) for price_element in price_elements]
titles = [title_element.find('span').get_text(strip=True) for title_element in title_elements]

# Определяем минимальное количество элементов
min_length = min(len(prices), len(titles))

# Обрезаем списки до минимальной длины
prices = prices[:min_length]
titles = titles[:min_length]

# Создаем DataFrame из списков цен и названий
df = pd.DataFrame({'Title': titles, 'Price': prices})

# Сохраняем DataFrame в CSV файл
df.to_csv('products.csv', index=False)

print("Цены и названия товаров успешно сохранены в файл products.csv")

# Закрываем WebDriver
driver.quit()
